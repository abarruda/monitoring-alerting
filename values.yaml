grafana:
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
      - name: Prometheus
        type: prometheus
        url: http://monitoring-alerting-prometheus-server.default.svc.cluster.local
        access: proxy
        isDefault: true
        jsonData:
          timeInterval: '5s'

  # sidecar:
  #   dashboards:
  #     enabled: true
  #     provider:
  #       disableDelete: true
  #       allowUiUpdates: false

  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
      - name: 'default'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: true
        editable: true
        options:
          path: /var/lib/grafana/dashboards

  dashboardsConfigMaps:
    default: "grafana-dashboards"

  env:
    GF_AUTH_ANONYMOUS_ENABLED: true
    GF_AUTH_ANONYMOUS_ORG_NAME: "Main Org."
    GF_AUTH_ANONYMOUS_ORG_ROLE: "Viewer"
    
  service:
    type: LoadBalancer
    loadBalancerIP:

prometheus:
  alertmanager:
    enabled: true
    image:
      repository: carlosedp/alertmanager
      tag: v0.16.2
    service:
      type: LoadBalancer
      loadBalancerIP: 
    persistentVolume:
      enabled: false
    resources:
      limits:
        memory: 64Mi
  kubeStateMetrics:
    enabled: true
  kube-state-metrics:
    image:
      repository: carlosedp/kube-state-metrics
      tag: v1.7.2-arm
  nodeExporter:
    enabled: true
    image:
      repository: prom/node-exporter-linux-armv7
      tag: v0.18.1
  pushgateway:
    enabled: false
  server:
    enabled: true
    image:
      repository: prom/prometheus-linux-armv7
      tag: v2.15.2
    service:
      type: LoadBalancer
      loadBalancerIP:
    resources:
      limits:
        memory: 256Mi
    persistentVolume:
      enabled: false
    emptyDir:
      sizeLimit: 10Gi
    retention: 14d

  alertmanagerFiles:
    custom-templates.tmpl: "{{ define \"smtp_to\" -}}email@here{{- end}}"

    alertmanager.yml:
      global:
        smtp_smarthost: 
        smtp_from: 
        smtp_auth_username:
        smtp_auth_password:

      templates:
        - /etc/config/custom-templates.tmpl

      receivers:
        - name: 'email'
          email_configs:
            - to: '{{ template "smtp_to" . }}'
              headers:
                subject: "[ {{ .CommonLabels.severity | toUpper }} ] Kubernetes cluster alert!"
              text: "{{ range .Alerts }}{{ .Annotations.summary }}:\n{{ .Annotations.description }}\n\n{{ end }}"
              html: ''
              send_resolved: true

      route:
        receiver: 'email'
        repeat_interval: 1h

  serverFiles:
    alerting_rules.yml:
      groups:

        - name: Nodes
          rules:
            - alert: NodeDown
              expr: kube_node_status_condition{condition="Ready",status="true"} == 0
              for: 1m
              labels:
                severity: critical
              annotations: 
                summary: 'Node(s) down'
                description: '{{ $labels.node }}'

        - name: Services
          rules:
            - alert: KubernetesPodNotHealthy
              expr: min_over_time(sum by (namespace, pod) (kube_pod_status_phase{phase=~"Pending|Unknown|Failed"})[10m:]) > 0
              for: 5m
              labels:
                severity: critical
              annotations:
                summary: "Kubernetes Pod(s) not healthy"
                description: "Pod '{{ $labels.pod }}' has been in a non-ready state for longer than 10 minutes."

            - alert: KubernetesPodCrashLooping
              expr: rate(kube_pod_container_status_restarts_total[15m]) * 60 * 5 > 5
              for: 5m
              labels:
                severity: critical
              annotations:
                summary: "Kubernetes pod crash looping"
                description: "Pod {{ $labels.pod }} is crash looping"

            - alert: KubernetesPodRestart
              expr: rate(kube_pod_container_status_restarts_total[5m]) > 0
              for: 1m
              labels:
                severity: warning
              annotations:
                summary: "Kubernetes pod restarted"
                description: "{{ $labels.pod }}"

            - alert: KubernetesReplicasSetMismatch
              expr: kube_replicaset_spec_replicas != kube_replicaset_status_ready_replicas
              for: 5m
              labels:
                severity: critical
              annotations:
                summary: "Kubernetes ReplicasSet mismatch"
                description: "{{ $labels.replicaset }}"

            - alert: KubernetesDeploymentReplicasMismatch
              expr: kube_deployment_spec_replicas != kube_deployment_status_replicas_available
              for: 5m
              labels:
                severity: critical
              annotations:
                summary: "Kubernetes Deployment replicas mismatch"
                description: "{{ $labels.deployment }}"

        - name: Volumes
          rules:
            - alert: KubernetesPersistentVolumeClaimPending
              expr: kube_persistentvolumeclaim_status_phase{phase="Pending"} == 1
              for: 5m
              labels:
                severity: critical
              annotations:
                summary: "Kubernetes PersistentVolumeClaim pending (instance {{ $labels.instance }})"
                description: "PersistentVolumeClaim {{ $labels.namespace }}/{{ $labels.persistentvolumeclaim }} is pending\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"

            - alert: KubernetesPersistentVolumeError
              expr: kube_persistentvolume_status_phase{phase=~"Failed|Pending"} > 0
              for: 5m
              labels:
                severity: critical
              annotations:
                summary: "Kubernetes PersistentVolume error (instance {{ $labels.instance }})"
                description: "Persistent volume is in bad state\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"

            - alert: KubernetesVolumeOutOfDiskSpace
              expr: kubelet_volume_stats_available_bytes / kubelet_volume_stats_capacity_bytes * 100 < 10
              for: 5m
              labels:
                severity: warning
              annotations:
                summary: "Kubernetes Volume out of disk space (instance {{ $labels.instance }})"
                description: "Volume is almost full (< 10% left)\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"
